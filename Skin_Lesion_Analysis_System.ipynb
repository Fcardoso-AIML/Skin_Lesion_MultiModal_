{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current environment: tf-clean\n",
            "LD_LIBRARY_PATH set: True\n",
            "TensorFlow version: 2.15.0\n",
            "GPUs found: 1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import numpy as np\n",
        "print(\"Current environment:\", os.environ.get('CONDA_DEFAULT_ENV', 'None'))\n",
        "print(\"LD_LIBRARY_PATH set:\", 'LD_LIBRARY_PATH' in os.environ)\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"GPUs found:\", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_jua3sDlfGL",
        "outputId": "cbe3644e-bcde-4532-9b67-b38bd540618f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /home/francisco_ardoso/.cache/kagglehub/datasets/kmader/skin-cancer-mnist-ham10000/versions/2\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"kmader/skin-cancer-mnist-ham10000\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "QhN9_SWHl5d3",
        "outputId": "a48251c8-ac0a-412c-beee-42e5e81e657e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "meta=pd.read_csv(os.path.join(path,\"HAM10000_metadata.csv\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "j3LK2Vqzpk1x",
        "outputId": "d2003c60-5798-4919-90a6-ee09a92b6161"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "lesion_id        object\n",
              "image_id         object\n",
              "dx               object\n",
              "dx_type          object\n",
              "age             float64\n",
              "sex              object\n",
              "localization     object\n",
              "dtype: object"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "meta.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UQyK9swspp8q",
        "outputId": "22bd1a25-e118-4dee-ee05-b1e4730e7d9a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lesion_id</th>\n",
              "      <th>image_id</th>\n",
              "      <th>dx</th>\n",
              "      <th>dx_type</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>localization</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0027419</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0025030</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0026769</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0025661</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HAM_0001466</td>\n",
              "      <td>ISIC_0031633</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>75.0</td>\n",
              "      <td>male</td>\n",
              "      <td>ear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10010</th>\n",
              "      <td>HAM_0002867</td>\n",
              "      <td>ISIC_0033084</td>\n",
              "      <td>akiec</td>\n",
              "      <td>histo</td>\n",
              "      <td>40.0</td>\n",
              "      <td>male</td>\n",
              "      <td>abdomen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10011</th>\n",
              "      <td>HAM_0002867</td>\n",
              "      <td>ISIC_0033550</td>\n",
              "      <td>akiec</td>\n",
              "      <td>histo</td>\n",
              "      <td>40.0</td>\n",
              "      <td>male</td>\n",
              "      <td>abdomen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10012</th>\n",
              "      <td>HAM_0002867</td>\n",
              "      <td>ISIC_0033536</td>\n",
              "      <td>akiec</td>\n",
              "      <td>histo</td>\n",
              "      <td>40.0</td>\n",
              "      <td>male</td>\n",
              "      <td>abdomen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10013</th>\n",
              "      <td>HAM_0000239</td>\n",
              "      <td>ISIC_0032854</td>\n",
              "      <td>akiec</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>face</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10014</th>\n",
              "      <td>HAM_0003521</td>\n",
              "      <td>ISIC_0032258</td>\n",
              "      <td>mel</td>\n",
              "      <td>histo</td>\n",
              "      <td>70.0</td>\n",
              "      <td>female</td>\n",
              "      <td>back</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9958 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         lesion_id      image_id     dx dx_type   age     sex localization\n",
              "0      HAM_0000118  ISIC_0027419    bkl   histo  80.0    male        scalp\n",
              "1      HAM_0000118  ISIC_0025030    bkl   histo  80.0    male        scalp\n",
              "2      HAM_0002730  ISIC_0026769    bkl   histo  80.0    male        scalp\n",
              "3      HAM_0002730  ISIC_0025661    bkl   histo  80.0    male        scalp\n",
              "4      HAM_0001466  ISIC_0031633    bkl   histo  75.0    male          ear\n",
              "...            ...           ...    ...     ...   ...     ...          ...\n",
              "10010  HAM_0002867  ISIC_0033084  akiec   histo  40.0    male      abdomen\n",
              "10011  HAM_0002867  ISIC_0033550  akiec   histo  40.0    male      abdomen\n",
              "10012  HAM_0002867  ISIC_0033536  akiec   histo  40.0    male      abdomen\n",
              "10013  HAM_0000239  ISIC_0032854  akiec   histo  80.0    male         face\n",
              "10014  HAM_0003521  ISIC_0032258    mel   histo  70.0  female         back\n",
              "\n",
              "[9958 rows x 7 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "meta.head()\n",
        "meta.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "SOUAS6WOqjQn",
        "outputId": "9496b624-7b0c-416c-80c7-c0b0fbb59149"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "age\n",
              "45.0    1299\n",
              "50.0    1187\n",
              "55.0    1009\n",
              "40.0     985\n",
              "60.0     803\n",
              "70.0     756\n",
              "35.0     753\n",
              "65.0     731\n",
              "75.0     618\n",
              "30.0     464\n",
              "80.0     404\n",
              "85.0     290\n",
              "25.0     247\n",
              "20.0     169\n",
              "5.0       86\n",
              "15.0      77\n",
              "10.0      41\n",
              "0.0       39\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "meta.age.value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "9xeYTJnZq7KF",
        "outputId": "80b73a1b-855a-41ac-c1f9-d7a40003c7fc"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.io as pio\n",
        "import streamlit as st\n",
        "def eda():\n",
        "    meta_clean = meta.dropna()\n",
        "\n",
        "    # Prep grouped counts\n",
        "    dx_counts = meta_clean[\"dx\"].value_counts().reset_index()\n",
        "    dx_counts.columns = [\"diagnosis\", \"count\"]\n",
        "\n",
        "    loc_counts = meta_clean[\"localization\"].value_counts().reset_index()\n",
        "    loc_counts.columns = [\"localization\", \"count\"]\n",
        "\n",
        "    # Create 2x2 grid + 1 full-width bottom row\n",
        "    fig = make_subplots(\n",
        "        rows=3, cols=2,\n",
        "        subplot_titles=(\n",
        "            \"Age Distribution\", \n",
        "            \"Diagnosis Counts\", \n",
        "            \"Sex Distribution\", \n",
        "            \"Lesion Localization\",\n",
        "            \"Age by Diagnosis & Sex\", \"\"\n",
        "        ),\n",
        "        specs=[\n",
        "            [{\"type\": \"xy\"}, {\"type\": \"xy\"}],\n",
        "            [{\"type\": \"domain\"}, {\"type\": \"xy\"}],   # <-- pie goes into domain\n",
        "            [{\"type\": \"xy\", \"colspan\": 2}, None]\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # --- 1) Age histogram\n",
        "    fig.add_trace(\n",
        "        go.Histogram(\n",
        "            x=meta_clean[\"age\"], nbinsx=30, opacity=0.7, name=\"Age\",\n",
        "            marker=dict(color=\"#1f77b4\")\n",
        "        ),\n",
        "        row=1, col=1\n",
        "    )\n",
        "\n",
        "    # --- 2) Diagnosis bar\n",
        "    fig.add_trace(\n",
        "        go.Bar(\n",
        "            x=dx_counts[\"diagnosis\"], \n",
        "            y=dx_counts[\"count\"], \n",
        "            name=\"Diagnosis\",\n",
        "            marker=dict(color=px.colors.qualitative.Dark2)\n",
        "        ),\n",
        "        row=1, col=2\n",
        "    )\n",
        "\n",
        "    # --- 3) Sex pie\n",
        "    fig.add_trace(\n",
        "        go.Pie(\n",
        "            labels=meta_clean[\"sex\"], \n",
        "            hole=0.4,\n",
        "            name=\"Sex\"\n",
        "        ),\n",
        "        row=2, col=1\n",
        "    )\n",
        "\n",
        "    # --- 4) Localization bar\n",
        "    fig.add_trace(\n",
        "        go.Bar(\n",
        "            x=loc_counts[\"localization\"], \n",
        "            y=loc_counts[\"count\"], \n",
        "            name=\"Localization\",\n",
        "            marker=dict(color=px.colors.qualitative.Pastel)\n",
        "        ),\n",
        "        row=2, col=2\n",
        "    )\n",
        "\n",
        "    # --- 5) Age vs Diagnosis (scatter instead of strip for compatibility)\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=meta_clean[\"dx\"], \n",
        "            y=meta_clean[\"age\"], \n",
        "            mode=\"markers\",\n",
        "            marker=dict(size=6, color=meta_clean[\"sex\"].map({\"male\": \"blue\", \"female\": \"red\"})),\n",
        "            name=\"Age by Dx & Sex\"\n",
        "        ),\n",
        "        row=3, col=1\n",
        "    )\n",
        "\n",
        "    # Layout\n",
        "    fig.update_layout(\n",
        "        title_text=\"HAM10000 Dataset Overview\",\n",
        "        height=900,\n",
        "        showlegend=True,\n",
        "        template=\"plotly_white\"\n",
        "    )\n",
        "\n",
        "    return st.plotly_chart(fig, use_container_width=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "8YfHt3d0rXRD",
        "outputId": "5d1153a3-e65d-4575-84ad-7722f80816a4"
      },
      "outputs": [],
      "source": [
        "#transform everything into categorical\n",
        "meta['label'] = meta['dx'].astype('category').cat.codes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7JQXPoVgps49",
        "outputId": "aa5de0a1-f300-4f69-fb57-46c296147671"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lesion_id</th>\n",
              "      <th>image_id</th>\n",
              "      <th>dx</th>\n",
              "      <th>dx_type</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>localization</th>\n",
              "      <th>label</th>\n",
              "      <th>file_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0027419</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>2</td>\n",
              "      <td>/home/francisco_ardoso/.cache/kagglehub/datase...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HAM_0000118</td>\n",
              "      <td>ISIC_0025030</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>2</td>\n",
              "      <td>/home/francisco_ardoso/.cache/kagglehub/datase...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0026769</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>2</td>\n",
              "      <td>/home/francisco_ardoso/.cache/kagglehub/datase...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>HAM_0002730</td>\n",
              "      <td>ISIC_0025661</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>80.0</td>\n",
              "      <td>male</td>\n",
              "      <td>scalp</td>\n",
              "      <td>2</td>\n",
              "      <td>/home/francisco_ardoso/.cache/kagglehub/datase...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HAM_0001466</td>\n",
              "      <td>ISIC_0031633</td>\n",
              "      <td>bkl</td>\n",
              "      <td>histo</td>\n",
              "      <td>75.0</td>\n",
              "      <td>male</td>\n",
              "      <td>ear</td>\n",
              "      <td>2</td>\n",
              "      <td>/home/francisco_ardoso/.cache/kagglehub/datase...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     lesion_id      image_id   dx dx_type   age   sex localization  label  \\\n",
              "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp      2   \n",
              "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp      2   \n",
              "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp      2   \n",
              "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp      2   \n",
              "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear      2   \n",
              "\n",
              "                                           file_path  \n",
              "0  /home/francisco_ardoso/.cache/kagglehub/datase...  \n",
              "1  /home/francisco_ardoso/.cache/kagglehub/datase...  \n",
              "2  /home/francisco_ardoso/.cache/kagglehub/datase...  \n",
              "3  /home/francisco_ardoso/.cache/kagglehub/datase...  \n",
              "4  /home/francisco_ardoso/.cache/kagglehub/datase...  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Attach image file paths as these will be the feature paths\n",
        "img_dir_1 = os.path.join(path, \"HAM10000_images_part_1\")\n",
        "img_dir_2 = os.path.join(path, \"HAM10000_images_part_2\")\n",
        "\n",
        "def get_path(image_id):\n",
        "    p1 = os.path.join(img_dir_1, image_id + \".jpg\")\n",
        "    p2 = os.path.join(img_dir_2, image_id + \".jpg\")\n",
        "    return p1 if os.path.exists(p1) else p2\n",
        "\n",
        "meta['file_path'] = meta['image_id'].apply(get_path)\n",
        "meta.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "a_4yQ2Z3qQ6U"
      },
      "outputs": [],
      "source": [
        "df=meta[[\"file_path\",\"dx\",\"label\"]]\n",
        "num_classes=len(df.label.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "yPn7hRwAsQHt",
        "outputId": "f91d9928-7a4d-4e40-b9e2-8902136b4dc4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2248/833956166.py:11: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
            "  plt.show()\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "df=meta\n",
        "row = df.iloc[0]\n",
        "\n",
        "img = mpimg.imread(row['file_path'])\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.title(f\"Label: {row['label']} (dx: {row['dx']})\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSmjsTxotGTB",
        "outputId": "bf77026a-acc3-4dac-9aea-7ef284af2226"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(450, 600, 3)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = meta['file_path'].values   # list of file paths\n",
        "y = meta['label'].values       # numeric labels\n",
        "img.shape #450 by 600, RGB=3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Kq0FGUAox-W2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tabular features shape: (10015, 3)\n",
            "Images: 10015\n",
            "Labels: 10015\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2248/2353864981.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  meta['age'].fillna(meta['age'].median(), inplace=True)\n",
            "/tmp/ipykernel_2248/2353864981.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  meta['sex'].fillna(meta['sex'].mode()[0], inplace=True)\n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "# ============================================================================\n",
        "# PREPARE DATA FOR BOTH MODELS (CV-only and Multimodal)\n",
        "# ============================================================================\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# Handle missing values\n",
        "meta['age'].fillna(meta['age'].median(), inplace=True)\n",
        "meta['sex'].fillna(meta['sex'].mode()[0], inplace=True)\n",
        "\n",
        "# Encode categorical variables for tabular features\n",
        "le_sex = LabelEncoder()\n",
        "le_loc = LabelEncoder()\n",
        "\n",
        "meta['sex_encoded'] = le_sex.fit_transform(meta['sex'])\n",
        "meta['localization_encoded'] = le_loc.fit_transform(meta['localization'])\n",
        "\n",
        "# Prepare data\n",
        "tabular_features = ['age', 'sex_encoded', 'localization_encoded']\n",
        "X_tabular = meta[tabular_features].values\n",
        "X_images = meta['file_path'].values\n",
        "y = meta['label'].values\n",
        "\n",
        "print(f\"Tabular features shape: {X_tabular.shape}\")\n",
        "print(f\"Images: {len(X_images)}\")\n",
        "print(f\"Labels: {len(y)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MC1tbvL2hfB",
        "outputId": "3cb503ad-74f4-4b3c-e8b7-c734e55b6cf1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train: 7010, Val: 1502, Test: 1503\n"
          ]
        }
      ],
      "source": [
        "# Split data for both models\n",
        "X_img_train, X_img_temp, X_tab_train, X_tab_temp, y_train, y_temp = train_test_split(\n",
        "    X_images, X_tabular, y, test_size=0.3, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "X_img_val, X_img_test, X_tab_val, X_tab_test, y_val, y_test = train_test_split(\n",
        "    X_img_temp, X_tab_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
        ")\n",
        "\n",
        "# Scale tabular features\n",
        "scaler = StandardScaler()\n",
        "X_tab_train = scaler.fit_transform(X_tab_train)\n",
        "X_tab_val = scaler.transform(X_tab_val)\n",
        "X_tab_test = scaler.transform(X_tab_test)\n",
        "\n",
        "print(f\"\\nTrain: {len(X_img_train)}, Val: {len(X_img_val)}, Test: {len(X_img_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Datasets created for both CV-only and Multimodal models\n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "# Processing functions\n",
        "IMG_SIZE = 224\n",
        "\n",
        "def process_image(file_path, label):\n",
        "    \"\"\"Process image for CV model\"\"\"\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE], method=\"bicubic\")\n",
        "    img = img / 255.0\n",
        "    return img, label\n",
        "\n",
        "def process_multimodal(file_path, tabular, label):\n",
        "    \"\"\"Process image + tabular for multimodal model\"\"\"\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE], method=\"bicubic\")\n",
        "    img = img / 255.0\n",
        "    return {'image': img, 'tabular': tabular}, label\n",
        "\n",
        "# %%\n",
        "# Creating datasets for BOTH models\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# CV-only datasets\n",
        "def make_cv_dataset(X_img, y, training=True):\n",
        "    ds = tf.data.Dataset.from_tensor_slices((X_img, y))\n",
        "    ds = ds.map(process_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    if training:\n",
        "        ds = ds.shuffle(1000)\n",
        "    return ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Multimodal datasets\n",
        "def make_multimodal_dataset(X_img, X_tab, y, training=True):\n",
        "    ds = tf.data.Dataset.from_tensor_slices((X_img, X_tab.astype(np.float32), y))\n",
        "    ds = ds.map(process_multimodal, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    if training:\n",
        "        ds = ds.shuffle(1000)\n",
        "    return ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Create CV-only datasets\n",
        "train_ds_cv = make_cv_dataset(X_img_train, y_train, training=True)\n",
        "val_ds_cv = make_cv_dataset(X_img_val, y_val, training=False)\n",
        "test_ds_cv = make_cv_dataset(X_img_test, y_test, training=False)\n",
        "\n",
        "# Create multimodal datasets\n",
        "train_ds_mm = make_multimodal_dataset(X_img_train, X_tab_train, y_train, training=True)\n",
        "val_ds_mm = make_multimodal_dataset(X_img_val, X_tab_val, y_val, training=False)\n",
        "test_ds_mm = make_multimodal_dataset(X_img_test, X_tab_test, y_test, training=False)\n",
        "\n",
        "print(\"âœ“ Datasets created for both CV-only and Multimodal models\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "vmOlHEzI17Iv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "MODEL 1: PURE COMPUTER VISION (IMAGE ONLY)\n",
            "======================================================================\n",
            "Model: \"HAM_ResNet_CV\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
            "                                                                 \n",
            " global_average_pooling2d (  (None, 2048)              0         \n",
            " GlobalAveragePooling2D)                                         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               262272    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 7)                 903       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23850887 (90.98 MB)\n",
            "Trainable params: 263175 (1.00 MB)\n",
            "Non-trainable params: 23587712 (89.98 MB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-01 11:12:36.870788: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
            "2025-10-01 11:12:37.079229: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:225] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 12.0\n",
            "2025-10-01 11:12:37.079303: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:228] Used ptxas at ptxas\n",
            "2025-10-01 11:12:37.079423: W external/local_xla/xla/stream_executor/gpu/redzone_allocator.cc:322] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
            "Relying on driver to perform ptx compilation. \n",
            "Modify $PATH to customize ptxas location.\n",
            "This message will be only logged once.\n",
            "2025-10-01 11:12:38.923462: W external/local_xla/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:504] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
            "Searched for CUDA in the following directories:\n",
            "  /usr/lib/nvidia-cuda-toolkit\n",
            "  /usr/local/cuda-12.2\n",
            "  /usr/local/cuda\n",
            "  /home/francisco_ardoso/miniconda3/envs/tf-clean/lib/python3.11/site-packages/tensorflow/python/platform/../../../nvidia/cuda_nvcc\n",
            "  /home/francisco_ardoso/miniconda3/envs/tf-clean/lib/python3.11/site-packages/tensorflow/python/platform/../../../../nvidia/cuda_nvcc\n",
            "  .\n",
            "You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n",
            "2025-10-01 11:12:38.969054: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-10-01 11:12:38.969134: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-10-01 11:12:38.969183: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-10-01 11:12:38.969215: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-10-01 11:12:38.969243: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-10-01 11:12:38.969269: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-10-01 11:12:38.969325: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-10-01 11:12:38.969360: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-10-01 11:12:38.969462: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-10-01 11:12:39.464868: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-10-01 11:12:39.611965: I external/local_xla/xla/service/service.cc:168] XLA service 0x287fcfd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2025-10-01 11:12:39.612034: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 5070 Laptop GPU, Compute Capability 12.0\n",
            "2025-10-01 11:12:39.633227: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2025-10-01 11:12:39.710619: W external/local_xla/xla/service/gpu/nvptx_compiler.cc:408] Couldn't read CUDA driver version.\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1759313559.736391    2418 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "220/220 [==============================] - 39s 127ms/step - loss: 2.0931 - accuracy: 0.1378 - val_loss: 1.9489 - val_accuracy: 0.1099\n",
            "Epoch 2/100\n",
            "220/220 [==============================] - 25s 113ms/step - loss: 1.9591 - accuracy: 0.0991 - val_loss: 1.9457 - val_accuracy: 0.0153\n",
            "Epoch 3/100\n",
            "220/220 [==============================] - 25s 113ms/step - loss: 1.9556 - accuracy: 0.1282 - val_loss: 1.9521 - val_accuracy: 0.0113\n",
            "Epoch 4/100\n",
            "220/220 [==============================] - 25s 111ms/step - loss: 1.9491 - accuracy: 0.1001 - val_loss: 2.1268 - val_accuracy: 0.0113\n",
            "Epoch 5/100\n",
            "220/220 [==============================] - 25s 112ms/step - loss: 1.9525 - accuracy: 0.0254 - val_loss: 2.0188 - val_accuracy: 0.0113\n",
            "Epoch 6/100\n",
            "220/220 [==============================] - 23s 103ms/step - loss: 1.9493 - accuracy: 0.0690 - val_loss: 1.9428 - val_accuracy: 0.0140\n",
            "Epoch 7/100\n",
            "220/220 [==============================] - 26s 116ms/step - loss: 1.9477 - accuracy: 0.2773 - val_loss: 1.9348 - val_accuracy: 0.6698\n",
            "Epoch 8/100\n",
            "220/220 [==============================] - 25s 114ms/step - loss: 1.9467 - accuracy: 0.0897 - val_loss: 1.9473 - val_accuracy: 0.0140\n",
            "Epoch 9/100\n",
            "220/220 [==============================] - 26s 117ms/step - loss: 1.9476 - accuracy: 0.1121 - val_loss: 1.9457 - val_accuracy: 0.0140\n",
            "Epoch 10/100\n",
            "220/220 [==============================] - 24s 106ms/step - loss: 1.9462 - accuracy: 0.0592 - val_loss: 1.9476 - val_accuracy: 0.0140\n",
            "Epoch 11/100\n",
            "220/220 [==============================] - 25s 114ms/step - loss: 1.9486 - accuracy: 0.0451 - val_loss: 1.9459 - val_accuracy: 0.0140\n",
            "Epoch 12/100\n",
            "220/220 [==============================] - 25s 114ms/step - loss: 1.9484 - accuracy: 0.0364 - val_loss: 1.9487 - val_accuracy: 0.0140\n",
            "Epoch 13/100\n",
            "220/220 [==============================] - 25s 113ms/step - loss: 1.9492 - accuracy: 0.1195 - val_loss: 1.9490 - val_accuracy: 0.0140\n",
            "Epoch 14/100\n",
            "220/220 [==============================] - 24s 105ms/step - loss: 1.9464 - accuracy: 0.0237 - val_loss: 1.9519 - val_accuracy: 0.0113\n",
            "Epoch 15/100\n",
            "220/220 [==============================] - 25s 114ms/step - loss: 1.9466 - accuracy: 0.0338 - val_loss: 1.9502 - val_accuracy: 0.0113\n",
            "Epoch 16/100\n",
            "220/220 [==============================] - 26s 114ms/step - loss: 1.9479 - accuracy: 0.0419 - val_loss: 1.9493 - val_accuracy: 0.1099\n",
            "Epoch 17/100\n",
            "220/220 [==============================] - 23s 104ms/step - loss: 1.9469 - accuracy: 0.0322 - val_loss: 1.9499 - val_accuracy: 0.1099\n",
            "\n",
            "CV Model - Initial Training Results\n",
            "47/47 [==============================] - 7s 147ms/step - loss: 1.9348 - accuracy: 0.6693\n",
            "Test Accuracy: 0.6693\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-01 11:20:26.285044: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.41GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2025-10-01 11:20:26.350341: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.41GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2025-10-01 11:20:43.172746: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2025-10-01 11:20:43.260137: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "220/220 [==============================] - 88s 228ms/step - loss: 1.6129 - accuracy: 0.5424 - val_loss: 1.5639 - val_accuracy: 0.6698\n",
            "Epoch 2/20\n",
            "220/220 [==============================] - 53s 238ms/step - loss: 1.0727 - accuracy: 0.6208 - val_loss: 2.7796 - val_accuracy: 0.6691\n",
            "Epoch 3/20\n",
            "220/220 [==============================] - 49s 219ms/step - loss: 0.8193 - accuracy: 0.6524 - val_loss: 2.2793 - val_accuracy: 0.0353\n",
            "Epoch 4/20\n",
            "220/220 [==============================] - 51s 232ms/step - loss: 0.6030 - accuracy: 0.7185 - val_loss: 1.6063 - val_accuracy: 0.3562\n",
            "Epoch 5/20\n",
            "220/220 [==============================] - 49s 219ms/step - loss: 0.4894 - accuracy: 0.7327 - val_loss: 1.2004 - val_accuracy: 0.6578\n",
            "Epoch 6/20\n",
            "220/220 [==============================] - 48s 218ms/step - loss: 0.3100 - accuracy: 0.8080 - val_loss: 0.6991 - val_accuracy: 0.7417\n",
            "Epoch 7/20\n",
            "220/220 [==============================] - 52s 233ms/step - loss: 0.2908 - accuracy: 0.8328 - val_loss: 0.7192 - val_accuracy: 0.7676\n",
            "Epoch 8/20\n",
            "220/220 [==============================] - 48s 218ms/step - loss: 0.2291 - accuracy: 0.8535 - val_loss: 1.1332 - val_accuracy: 0.7164\n",
            "Epoch 9/20\n",
            "220/220 [==============================] - 52s 235ms/step - loss: 0.2621 - accuracy: 0.8399 - val_loss: 0.6141 - val_accuracy: 0.7929\n",
            "Epoch 10/20\n",
            "220/220 [==============================] - 49s 220ms/step - loss: 0.1231 - accuracy: 0.9064 - val_loss: 0.6563 - val_accuracy: 0.7876\n",
            "Epoch 11/20\n",
            "220/220 [==============================] - 52s 236ms/step - loss: 0.1178 - accuracy: 0.9021 - val_loss: 0.8257 - val_accuracy: 0.7956\n",
            "Epoch 12/20\n",
            "220/220 [==============================] - 49s 221ms/step - loss: 0.1235 - accuracy: 0.9250 - val_loss: 1.0515 - val_accuracy: 0.7324\n",
            "Epoch 13/20\n",
            "220/220 [==============================] - 48s 215ms/step - loss: 0.1449 - accuracy: 0.8817 - val_loss: 1.4003 - val_accuracy: 0.7230\n",
            "Epoch 14/20\n",
            "220/220 [==============================] - 53s 238ms/step - loss: 0.8281 - accuracy: 0.6051 - val_loss: 0.8587 - val_accuracy: 0.7150\n",
            "Epoch 15/20\n",
            "220/220 [==============================] - 50s 226ms/step - loss: 0.2804 - accuracy: 0.8230 - val_loss: 0.7567 - val_accuracy: 0.7683\n",
            "Epoch 16/20\n",
            "220/220 [==============================] - 54s 242ms/step - loss: 0.1260 - accuracy: 0.8977 - val_loss: 0.6170 - val_accuracy: 0.8216\n",
            "Epoch 17/20\n",
            "220/220 [==============================] - 50s 225ms/step - loss: 0.0690 - accuracy: 0.9352 - val_loss: 0.8369 - val_accuracy: 0.7989\n",
            "Epoch 18/20\n",
            "220/220 [==============================] - 53s 240ms/step - loss: 0.1366 - accuracy: 0.9073 - val_loss: 3.8330 - val_accuracy: 0.4927\n",
            "Epoch 19/20\n",
            "220/220 [==============================] - 52s 235ms/step - loss: 0.0938 - accuracy: 0.9344 - val_loss: 0.6874 - val_accuracy: 0.8342\n",
            "Epoch 20/20\n",
            "220/220 [==============================] - 51s 229ms/step - loss: 0.0383 - accuracy: 0.9705 - val_loss: 0.7912 - val_accuracy: 0.8349\n",
            "47/47 [==============================] - 4s 84ms/step - loss: 0.6913 - accuracy: 0.8523\n",
            "CV Test Accuracy (final): 0.8523\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "# %%\n",
        "print(\"=\"*70)\n",
        "print(\"MODEL 1: PURE COMPUTER VISION (IMAGE ONLY)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "base_model_cv = ResNet50(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_shape=(224, 224, 3)\n",
        ")\n",
        "base_model_cv.trainable = False\n",
        "\n",
        "model_cv = models.Sequential([\n",
        "    base_model_cv,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(128, activation='relu'),  # Add extra layer\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "], name=\"HAM_ResNet_CV\")\n",
        "\n",
        "model_cv.summary()\n",
        "\n",
        "# %%\n",
        "# Compile and train CV model\n",
        "model_cv.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "class_weights_array = compute_class_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights_array))\n",
        "\n",
        "callbacks_cv = [\n",
        "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "    ModelCheckpoint('best_model_cv.keras', save_best_only=True, monitor='val_accuracy')\n",
        "]\n",
        "\n",
        "history_cv = model_cv.fit(\n",
        "    train_ds_cv,  # Changed to train_ds_cv\n",
        "    validation_data=val_ds_cv,  # Changed\n",
        "    epochs=100,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=callbacks_cv\n",
        ")\n",
        "\n",
        "# %%\n",
        "# Evaluate CV model\n",
        "print(\"\\nCV Model - Initial Training Results\")\n",
        "test_loss_cv_initial, test_accuracy_cv_initial = model_cv.evaluate(test_ds_cv)\n",
        "print(f\"Test Accuracy: {test_accuracy_cv_initial:.4f}\")\n",
        "\n",
        "# %%\n",
        "# Fine-tune CV model\n",
        "base_model_cv.trainable = True\n",
        "\n",
        "model_cv.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history_cv_finetune = model_cv.fit(\n",
        "    train_ds_cv,\n",
        "    validation_data=val_ds_cv,\n",
        "    epochs=20,\n",
        "    class_weight=class_weights\n",
        ")\n",
        "\n",
        "test_loss_cv, test_accuracy_cv = model_cv.evaluate(test_ds_cv)\n",
        "print(f\"CV Test Accuracy (final): {test_accuracy_cv:.4f}\")\n",
        "\n",
        "model_cv.save('HAM_ResNet_CV_final.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "MODEL 2: MULTIMODAL (IMAGE + TABULAR)\n",
            "======================================================================\n",
            "Model: \"HAM_ResNet_Multimodal\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " tabular (InputLayer)        [(None, 3)]                  0         []                            \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 64)                   256       ['tabular[0][0]']             \n",
            "                                                                                                  \n",
            " image (InputLayer)          [(None, 224, 224, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 64)                   256       ['dense_1[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " resnet50 (Functional)       (None, None, None, 2048)     2358771   ['image[0][0]']               \n",
            "                                                          2                                       \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 64)                   0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " global_average_pooling2d (  (None, 2048)                 0         ['resnet50[0][0]']            \n",
            " GlobalAveragePooling2D)                                                                          \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 64)                   4160      ['dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 2048)                 0         ['global_average_pooling2d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 64)                   256       ['dense_2[0][0]']             \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 128)                  262272    ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 32)                   2080      ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 160)                  0         ['dense[0][0]',               \n",
            "                                                                     'dense_3[0][0]']             \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 64)                   10304     ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 64)                   0         ['dense_4[0][0]']             \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 7)                    455       ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23867751 (91.05 MB)\n",
            "Trainable params: 279783 (1.07 MB)\n",
            "Non-trainable params: 23587968 (89.98 MB)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-01 11:43:36.820817: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-10-01 11:43:36.828066: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-10-01 11:43:36.831928: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-10-01 11:43:36.832610: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-10-01 11:43:36.832751: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-10-01 11:43:36.834286: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-10-01 11:43:36.834424: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-10-01 11:43:36.834606: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-10-01 11:43:37.181587: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
            "2025-10-01 11:43:37.880974: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "220/220 [==============================] - 35s 129ms/step - loss: 1.9364 - accuracy: 0.2392 - val_loss: 1.8424 - val_accuracy: 0.2310\n",
            "Epoch 2/100\n",
            "220/220 [==============================] - 26s 117ms/step - loss: 1.8321 - accuracy: 0.2526 - val_loss: 1.7985 - val_accuracy: 0.2477\n",
            "Epoch 3/100\n",
            "220/220 [==============================] - 28s 124ms/step - loss: 1.8067 - accuracy: 0.2213 - val_loss: 1.6538 - val_accuracy: 0.3489\n",
            "Epoch 4/100\n",
            "220/220 [==============================] - 23s 104ms/step - loss: 1.7622 - accuracy: 0.2392 - val_loss: 1.6697 - val_accuracy: 0.1977\n",
            "Epoch 5/100\n",
            "220/220 [==============================] - 26s 115ms/step - loss: 1.7605 - accuracy: 0.2425 - val_loss: 1.6930 - val_accuracy: 0.1485\n",
            "Epoch 6/100\n",
            "220/220 [==============================] - 26s 117ms/step - loss: 1.7448 - accuracy: 0.2231 - val_loss: 1.6386 - val_accuracy: 0.1791\n",
            "Epoch 7/100\n",
            "220/220 [==============================] - 26s 117ms/step - loss: 1.7518 - accuracy: 0.2190 - val_loss: 1.6309 - val_accuracy: 0.1877\n",
            "Epoch 8/100\n",
            "220/220 [==============================] - 23s 103ms/step - loss: 1.7428 - accuracy: 0.2007 - val_loss: 1.6583 - val_accuracy: 0.1731\n",
            "Epoch 9/100\n",
            "220/220 [==============================] - 26s 118ms/step - loss: 1.7329 - accuracy: 0.2011 - val_loss: 1.6083 - val_accuracy: 0.2876\n",
            "Epoch 10/100\n",
            "220/220 [==============================] - 26s 116ms/step - loss: 1.7123 - accuracy: 0.2271 - val_loss: 1.7182 - val_accuracy: 0.1971\n",
            "Epoch 11/100\n",
            "220/220 [==============================] - 23s 104ms/step - loss: 1.7114 - accuracy: 0.2047 - val_loss: 1.6414 - val_accuracy: 0.2643\n",
            "Epoch 12/100\n",
            "220/220 [==============================] - 26s 117ms/step - loss: 1.6998 - accuracy: 0.2496 - val_loss: 1.6417 - val_accuracy: 0.3382\n",
            "Epoch 13/100\n",
            "220/220 [==============================] - 25s 114ms/step - loss: 1.7004 - accuracy: 0.2496 - val_loss: 1.6599 - val_accuracy: 0.2357\n",
            "Epoch 14/100\n",
            "220/220 [==============================] - 26s 115ms/step - loss: 1.6984 - accuracy: 0.2488 - val_loss: 1.6188 - val_accuracy: 0.2883\n",
            "Epoch 15/100\n",
            "220/220 [==============================] - 23s 104ms/step - loss: 1.6986 - accuracy: 0.2688 - val_loss: 1.6059 - val_accuracy: 0.3302\n",
            "Epoch 16/100\n",
            "220/220 [==============================] - 25s 113ms/step - loss: 1.7047 - accuracy: 0.2544 - val_loss: 1.6180 - val_accuracy: 0.3156\n",
            "Epoch 17/100\n",
            "220/220 [==============================] - 26s 117ms/step - loss: 1.6913 - accuracy: 0.2435 - val_loss: 1.6575 - val_accuracy: 0.2630\n",
            "Epoch 18/100\n",
            "220/220 [==============================] - 25s 114ms/step - loss: 1.7020 - accuracy: 0.2411 - val_loss: 1.6659 - val_accuracy: 0.2923\n",
            "Epoch 19/100\n",
            "220/220 [==============================] - 23s 102ms/step - loss: 1.6803 - accuracy: 0.2806 - val_loss: 1.6185 - val_accuracy: 0.3029\n",
            "Epoch 20/100\n",
            "220/220 [==============================] - 25s 113ms/step - loss: 1.6857 - accuracy: 0.2464 - val_loss: 1.6675 - val_accuracy: 0.2523\n",
            "Epoch 21/100\n",
            "220/220 [==============================] - 25s 113ms/step - loss: 1.6696 - accuracy: 0.2524 - val_loss: 1.6787 - val_accuracy: 0.2350\n",
            "Epoch 22/100\n",
            "220/220 [==============================] - 23s 101ms/step - loss: 1.6767 - accuracy: 0.2753 - val_loss: 1.6182 - val_accuracy: 0.2803\n",
            "Epoch 23/100\n",
            "220/220 [==============================] - 26s 115ms/step - loss: 1.6645 - accuracy: 0.2616 - val_loss: 1.5673 - val_accuracy: 0.3469\n",
            "Epoch 24/100\n",
            "220/220 [==============================] - 26s 115ms/step - loss: 1.6516 - accuracy: 0.2723 - val_loss: 1.6750 - val_accuracy: 0.2463\n",
            "Epoch 25/100\n",
            "220/220 [==============================] - 26s 115ms/step - loss: 1.6548 - accuracy: 0.2688 - val_loss: 1.6637 - val_accuracy: 0.2217\n",
            "Epoch 26/100\n",
            "220/220 [==============================] - 22s 101ms/step - loss: 1.6484 - accuracy: 0.2588 - val_loss: 1.6692 - val_accuracy: 0.2190\n",
            "Epoch 27/100\n",
            "220/220 [==============================] - 26s 115ms/step - loss: 1.6668 - accuracy: 0.2462 - val_loss: 1.6714 - val_accuracy: 0.2390\n",
            "Epoch 28/100\n",
            "220/220 [==============================] - 25s 113ms/step - loss: 1.6665 - accuracy: 0.2478 - val_loss: 1.6054 - val_accuracy: 0.3229\n",
            "Epoch 29/100\n",
            "220/220 [==============================] - 23s 102ms/step - loss: 1.6484 - accuracy: 0.2843 - val_loss: 1.6201 - val_accuracy: 0.3262\n",
            "Epoch 30/100\n",
            "220/220 [==============================] - 25s 113ms/step - loss: 1.6353 - accuracy: 0.2756 - val_loss: 1.6220 - val_accuracy: 0.2969\n",
            "Epoch 31/100\n",
            "220/220 [==============================] - 25s 114ms/step - loss: 1.6473 - accuracy: 0.2709 - val_loss: 1.5951 - val_accuracy: 0.2830\n",
            "Epoch 32/100\n",
            "220/220 [==============================] - 23s 101ms/step - loss: 1.6635 - accuracy: 0.2461 - val_loss: 1.6158 - val_accuracy: 0.3043\n",
            "Epoch 33/100\n",
            "220/220 [==============================] - 26s 115ms/step - loss: 1.6504 - accuracy: 0.2553 - val_loss: 1.6752 - val_accuracy: 0.2443\n",
            "\n",
            "Multimodal Model - Initial Training Results\n",
            "47/47 [==============================] - 4s 81ms/step - loss: 1.5680 - accuracy: 0.3506\n",
            "Test Accuracy: 0.3506\n",
            "Epoch 1/20\n",
            "220/220 [==============================] - 88s 236ms/step - loss: 1.9309 - accuracy: 0.6170 - val_loss: 1.6828 - val_accuracy: 0.6591\n",
            "Epoch 2/20\n",
            "220/220 [==============================] - 49s 222ms/step - loss: 1.5296 - accuracy: 0.6117 - val_loss: 2.4314 - val_accuracy: 0.6691\n",
            "Epoch 3/20\n",
            "220/220 [==============================] - 51s 230ms/step - loss: 1.4905 - accuracy: 0.6117 - val_loss: 2.0936 - val_accuracy: 0.5846\n",
            "Epoch 4/20\n",
            "220/220 [==============================] - 49s 219ms/step - loss: 1.4429 - accuracy: 0.6207 - val_loss: 1.2892 - val_accuracy: 0.5513\n",
            "Epoch 5/20\n",
            "220/220 [==============================] - 50s 227ms/step - loss: 1.4083 - accuracy: 0.6389 - val_loss: 0.9941 - val_accuracy: 0.6345\n",
            "Epoch 6/20\n",
            "220/220 [==============================] - 47s 214ms/step - loss: 1.3536 - accuracy: 0.6489 - val_loss: 0.8701 - val_accuracy: 0.6884\n",
            "Epoch 7/20\n",
            "220/220 [==============================] - 48s 215ms/step - loss: 1.3152 - accuracy: 0.6509 - val_loss: 0.8582 - val_accuracy: 0.6864\n",
            "Epoch 8/20\n",
            "220/220 [==============================] - 51s 229ms/step - loss: 1.2608 - accuracy: 0.6601 - val_loss: 0.8349 - val_accuracy: 0.7024\n",
            "Epoch 9/20\n",
            "220/220 [==============================] - 48s 216ms/step - loss: 1.2244 - accuracy: 0.6883 - val_loss: 0.8226 - val_accuracy: 0.7024\n",
            "Epoch 10/20\n",
            "220/220 [==============================] - 50s 226ms/step - loss: 1.1742 - accuracy: 0.6802 - val_loss: 0.8260 - val_accuracy: 0.7031\n",
            "Epoch 11/20\n",
            "220/220 [==============================] - 47s 214ms/step - loss: 1.1177 - accuracy: 0.7061 - val_loss: 0.8016 - val_accuracy: 0.7144\n",
            "Epoch 12/20\n",
            "220/220 [==============================] - 50s 228ms/step - loss: 1.0731 - accuracy: 0.7153 - val_loss: 0.7646 - val_accuracy: 0.7250\n",
            "Epoch 13/20\n",
            "220/220 [==============================] - 48s 215ms/step - loss: 0.9916 - accuracy: 0.7358 - val_loss: 0.7592 - val_accuracy: 0.7324\n",
            "Epoch 14/20\n",
            "220/220 [==============================] - 48s 214ms/step - loss: 0.9319 - accuracy: 0.7516 - val_loss: 0.7270 - val_accuracy: 0.7443\n",
            "Epoch 15/20\n",
            "220/220 [==============================] - 52s 235ms/step - loss: 0.8140 - accuracy: 0.7618 - val_loss: 0.7140 - val_accuracy: 0.7550\n",
            "Epoch 16/20\n",
            "220/220 [==============================] - 49s 223ms/step - loss: 0.7363 - accuracy: 0.7803 - val_loss: 0.7118 - val_accuracy: 0.7630\n",
            "Epoch 17/20\n",
            "220/220 [==============================] - 52s 233ms/step - loss: 0.6395 - accuracy: 0.7990 - val_loss: 0.6595 - val_accuracy: 0.7823\n",
            "Epoch 18/20\n",
            "220/220 [==============================] - 50s 224ms/step - loss: 0.5444 - accuracy: 0.8208 - val_loss: 0.6360 - val_accuracy: 0.7936\n",
            "Epoch 19/20\n",
            "220/220 [==============================] - 52s 237ms/step - loss: 0.4851 - accuracy: 0.8324 - val_loss: 0.6259 - val_accuracy: 0.8029\n",
            "Epoch 20/20\n",
            "220/220 [==============================] - 50s 226ms/step - loss: 0.4101 - accuracy: 0.8526 - val_loss: 0.6035 - val_accuracy: 0.8162\n",
            "47/47 [==============================] - 4s 82ms/step - loss: 0.6388 - accuracy: 0.8031\n",
            "Multimodal Test Accuracy (final): 0.8031\n",
            "\n",
            "======================================================================\n",
            "MODEL COMPARISON\n",
            "======================================================================\n",
            "CV-Only:    0.8523 (85.23%)\n",
            "Multimodal: 0.8031 (80.31%)\n",
            "Improvement: -4.92%\n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MODEL 2: MULTIMODAL (IMAGE + TABULAR)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "from tensorflow.keras import Input, Model\n",
        "\n",
        "# Image input branch\n",
        "image_input = Input(shape=(224, 224, 3), name='image')\n",
        "base_resnet = ResNet50(include_top=False, weights='imagenet')(image_input)\n",
        "x = layers.GlobalAveragePooling2D()(base_resnet)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "image_features = layers.Dense(128, activation='relu')(x)\n",
        "\n",
        "# Tabular input branch\n",
        "tabular_input = Input(shape=(len(tabular_features),), name='tabular')\n",
        "tab = layers.Dense(64, activation='relu')(tabular_input)\n",
        "tab = layers.BatchNormalization()(tab)\n",
        "tab = layers.Dropout(0.3)(tab)\n",
        "tab = layers.Dense(64, activation='relu')(tab)\n",
        "tab = layers.BatchNormalization()(tab)\n",
        "tab = layers.Dense(32, activation='relu')(tab)\n",
        "\n",
        "# Combine both branches\n",
        "combined = layers.concatenate([image_features, tab])\n",
        "combined = layers.Dense(64, activation='relu')(combined)\n",
        "combined = layers.Dropout(0.3)(combined)\n",
        "output = layers.Dense(num_classes, activation='softmax')(combined)\n",
        "\n",
        "# Create model\n",
        "model_mm = Model(\n",
        "    inputs=[image_input, tabular_input],\n",
        "    outputs=output,\n",
        "    name=\"HAM_ResNet_Multimodal\"\n",
        ")\n",
        "\n",
        "# Freeze ResNet base\n",
        "for layer in model_mm.layers:\n",
        "    if isinstance(layer, tf.keras.Model):\n",
        "        layer.trainable = False\n",
        "\n",
        "model_mm.summary()\n",
        "\n",
        "# %%\n",
        "# Compile and train multimodal\n",
        "model_mm.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "callbacks_mm = [\n",
        "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "    ModelCheckpoint('best_model_mm.keras', save_best_only=True, monitor='val_accuracy')\n",
        "]\n",
        "\n",
        "history_mm = model_mm.fit(\n",
        "    train_ds_mm,\n",
        "    validation_data=val_ds_mm,\n",
        "    epochs=100,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=callbacks_mm\n",
        ")\n",
        "\n",
        "# %%\n",
        "# Evaluate multimodal\n",
        "print(\"\\nMultimodal Model - Initial Training Results\")\n",
        "test_loss_mm_initial, test_accuracy_mm_initial = model_mm.evaluate(test_ds_mm)\n",
        "print(f\"Test Accuracy: {test_accuracy_mm_initial:.4f}\")\n",
        "\n",
        "# %%\n",
        "# Fine-tune multimodal\n",
        "for layer in model_mm.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "model_mm.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history_mm_finetune = model_mm.fit(\n",
        "    train_ds_mm,\n",
        "    validation_data=val_ds_mm,\n",
        "    epochs=20,\n",
        "    class_weight=class_weights\n",
        ")\n",
        "\n",
        "test_loss_mm, test_accuracy_mm = model_mm.evaluate(test_ds_mm)\n",
        "print(f\"Multimodal Test Accuracy (final): {test_accuracy_mm:.4f}\")\n",
        "\n",
        "model_mm.save('HAM_ResNet_Multimodal_final.keras')\n",
        "\n",
        "# %%\n",
        "# COMPARISON\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MODEL COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "print(f\"CV-Only:    {test_accuracy_cv:.4f} ({test_accuracy_cv*100:.2f}%)\")\n",
        "print(f\"Multimodal: {test_accuracy_mm:.4f} ({test_accuracy_mm*100:.2f}%)\")\n",
        "improvement = (test_accuracy_mm - test_accuracy_cv) * 100\n",
        "print(f\"Improvement: {improvement:+.2f}%\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47/47 [==============================] - 5s 83ms/step\n",
            "47/47 [==============================] - 5s 78ms/step\n",
            "\n",
            "âœ“ All files saved!\n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "# Save everything for Streamlit\n",
        "import pickle\n",
        "import joblib\n",
        "\n",
        "np.save('y_pred_cv.npy', np.argmax(model_cv.predict(test_ds_cv), axis=1))\n",
        "np.save('y_pred_mm.npy', np.argmax(model_mm.predict(test_ds_mm), axis=1))\n",
        "np.save('y_test.npy', y_test)\n",
        "\n",
        "with open('histories.pkl', 'wb') as f:\n",
        "    pickle.dump({\n",
        "        'history_cv': history_cv.history,\n",
        "        'history_cv_finetune': history_cv_finetune.history,\n",
        "        'history_mm': history_mm.history,\n",
        "        'history_mm_finetune': history_mm_finetune.history\n",
        "    }, f)\n",
        "\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "joblib.dump(le_sex, 'le_sex.pkl')\n",
        "joblib.dump(le_loc, 'le_loc.pkl')\n",
        "\n",
        "print(\"\\nâœ“ All files saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating predictions for both models...\n",
            "47/47 [==============================] - 4s 79ms/step\n",
            "47/47 [==============================] - 4s 78ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2248/1295861189.py:60: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
            "  plt.show()\n",
            "/tmp/ipykernel_2248/1295861189.py:84: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
            "  plt.show()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "CV MODEL - CLASSIFICATION REPORT\n",
            "======================================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       akiec     0.6111    0.6735    0.6408        49\n",
            "         bcc     0.7714    0.7013    0.7347        77\n",
            "         bkl     0.8029    0.6667    0.7285       165\n",
            "          df     0.8182    0.5294    0.6429        17\n",
            "         mel     0.6605    0.6407    0.6505       167\n",
            "          nv     0.9089    0.9423    0.9253      1006\n",
            "        vasc     0.7692    0.9091    0.8333        22\n",
            "\n",
            "    accuracy                         0.8523      1503\n",
            "   macro avg     0.7632    0.7233    0.7366      1503\n",
            "weighted avg     0.8499    0.8523    0.8496      1503\n",
            "\n",
            "\n",
            "======================================================================\n",
            "MULTIMODAL MODEL - CLASSIFICATION REPORT\n",
            "======================================================================\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       akiec     0.5224    0.7143    0.6034        49\n",
            "         bcc     0.6744    0.7532    0.7117        77\n",
            "         bkl     0.5714    0.6545    0.6102       165\n",
            "          df     0.6667    0.5882    0.6250        17\n",
            "         mel     0.5149    0.6228    0.5637       167\n",
            "          nv     0.9552    0.8688    0.9099      1006\n",
            "        vasc     0.6207    0.8182    0.7059        22\n",
            "\n",
            "    accuracy                         0.8031      1503\n",
            "   macro avg     0.6465    0.7171    0.6757      1503\n",
            "weighted avg     0.8275    0.8031    0.8122      1503\n",
            "\n",
            "\n",
            "======================================================================\n",
            "SUMMARY\n",
            "======================================================================\n",
            "CV Model Accuracy: 0.8523\n",
            "Multimodal Accuracy: 0.8031\n",
            "Improvement: -4.92%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2248/1295861189.py:121: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
            "  plt.show()\n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "# ============================================================================\n",
        "# VISUALIZATION: COMPARE BOTH MODELS\n",
        "# ============================================================================\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
        "\n",
        "# Get predictions for both models\n",
        "print(\"Generating predictions for both models...\")\n",
        "y_pred_cv_probs = model_cv.predict(test_ds_cv)\n",
        "y_pred_cv = np.argmax(y_pred_cv_probs, axis=1)\n",
        "\n",
        "y_pred_mm_probs = model_mm.predict(test_ds_mm)\n",
        "y_pred_mm = np.argmax(y_pred_mm_probs, axis=1)\n",
        "\n",
        "class_names = meta['dx'].astype('category').cat.categories.tolist()\n",
        "\n",
        "# %%\n",
        "# 1. TRAINING HISTORY COMPARISON\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "fig.suptitle('Training History Comparison: CV vs Multimodal', fontsize=16, fontweight='bold')\n",
        "\n",
        "# CV Model\n",
        "axes[0, 0].plot(history_cv.history['accuracy'], label='CV Train', linewidth=2, color='#1f77b4')\n",
        "axes[0, 0].plot(history_cv.history['val_accuracy'], label='CV Val', linewidth=2, color='#ff7f0e')\n",
        "axes[0, 0].set_title('CV Model - Accuracy')\n",
        "axes[0, 0].set_xlabel('Epoch')\n",
        "axes[0, 0].set_ylabel('Accuracy')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[0, 1].plot(history_cv.history['loss'], label='CV Train', linewidth=2, color='#1f77b4')\n",
        "axes[0, 1].plot(history_cv.history['val_loss'], label='CV Val', linewidth=2, color='#ff7f0e')\n",
        "axes[0, 1].set_title('CV Model - Loss')\n",
        "axes[0, 1].set_xlabel('Epoch')\n",
        "axes[0, 1].set_ylabel('Loss')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Multimodal Model\n",
        "axes[1, 0].plot(history_mm.history['accuracy'], label='MM Train', linewidth=2, color='#2ca02c')\n",
        "axes[1, 0].plot(history_mm.history['val_accuracy'], label='MM Val', linewidth=2, color='#d62728')\n",
        "axes[1, 0].set_title('Multimodal Model - Accuracy')\n",
        "axes[1, 0].set_xlabel('Epoch')\n",
        "axes[1, 0].set_ylabel('Accuracy')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1, 1].plot(history_mm.history['loss'], label='MM Train', linewidth=2, color='#2ca02c')\n",
        "axes[1, 1].plot(history_mm.history['val_loss'], label='MM Val', linewidth=2, color='#d62728')\n",
        "axes[1, 1].set_title('Multimodal Model - Loss')\n",
        "axes[1, 1].set_xlabel('Epoch')\n",
        "axes[1, 1].set_ylabel('Loss')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# %%\n",
        "# 2. SIDE-BY-SIDE CONFUSION MATRICES\n",
        "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
        "\n",
        "# CV Model Confusion Matrix\n",
        "cm_cv = confusion_matrix(y_test, y_pred_cv)\n",
        "sns.heatmap(cm_cv, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=class_names, yticklabels=class_names, ax=axes[0])\n",
        "axes[0].set_title(f'CV Model (Acc: {test_accuracy_cv:.4f})', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Predicted')\n",
        "axes[0].set_ylabel('True')\n",
        "\n",
        "# Multimodal Confusion Matrix\n",
        "cm_mm = confusion_matrix(y_test, y_pred_mm)\n",
        "sns.heatmap(cm_mm, annot=True, fmt='d', cmap='Greens',\n",
        "            xticklabels=class_names, yticklabels=class_names, ax=axes[1])\n",
        "axes[1].set_title(f'Multimodal Model (Acc: {test_accuracy_mm:.4f})', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xlabel('Predicted')\n",
        "axes[1].set_ylabel('True')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('confusion_matrices_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# %%\n",
        "# 3. PER-CLASS F1-SCORE COMPARISON\n",
        "precision_cv, recall_cv, f1_cv, support_cv = precision_recall_fscore_support(\n",
        "    y_test, y_pred_cv, labels=range(num_classes)\n",
        ")\n",
        "\n",
        "precision_mm, recall_mm, f1_mm, support_mm = precision_recall_fscore_support(\n",
        "    y_test, y_pred_mm, labels=range(num_classes)\n",
        ")\n",
        "\n",
        "x = np.arange(len(class_names))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "bars1 = ax.bar(x - width/2, f1_cv, width, label='CV Model', alpha=0.8, color='#1f77b4')\n",
        "bars2 = ax.bar(x + width/2, f1_mm, width, label='Multimodal', alpha=0.8, color='#2ca02c')\n",
        "\n",
        "ax.set_xlabel('Diagnosis Type', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('F1-Score', fontsize=12, fontweight='bold')\n",
        "ax.set_title('F1-Score Comparison by Class', fontsize=16, fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(class_names, rotation=45, ha='right')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "ax.set_ylim([0, 1])\n",
        "\n",
        "# Add value labels\n",
        "for bars in [bars1, bars2]:\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{height:.2f}', ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('f1_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# %%\n",
        "# 4. CLASSIFICATION REPORTS\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CV MODEL - CLASSIFICATION REPORT\")\n",
        "print(\"=\"*70)\n",
        "print(classification_report(y_test, y_pred_cv, target_names=class_names, digits=4))\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MULTIMODAL MODEL - CLASSIFICATION REPORT\")\n",
        "print(\"=\"*70)\n",
        "print(classification_report(y_test, y_pred_mm, target_names=class_names, digits=4))\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "print(f\"CV Model Accuracy: {test_accuracy_cv:.4f}\")\n",
        "print(f\"Multimodal Accuracy: {test_accuracy_mm:.4f}\")\n",
        "print(f\"Improvement: {(test_accuracy_mm - test_accuracy_cv)*100:+.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/francisco_ardoso/miniconda3/envs/tf-clean/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: HAM_ResNet_final/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: HAM_ResNet_final/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Model saved in SavedModel format\n",
            "âœ“ Model saved!\n",
            "âœ“ Weights saved\n"
          ]
        }
      ],
      "source": [
        "model_cv.save_weights('model_weights.h5')\n",
        "model_cv.save('HAM_ResNet_final.keras')  \n",
        "model_cv.save('HAM_ResNet_final.h5')     \n",
        "model_cv.save('HAM_ResNet_final')  # This creates a directory\n",
        "print(\"âœ“ Model saved in SavedModel format\")\n",
        "print(\"âœ“ Model saved!\")\n",
        "print(\"âœ“ Weights saved\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf-clean",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
